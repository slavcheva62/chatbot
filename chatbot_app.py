# -*- coding: utf-8 -*-
import traceback
import datetime

def log(msg):
    with open("log.txt", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.datetime.now().isoformat()}] {msg}\n")

log("üîÑ –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ —á–∞—Ç–±–æ—Ç–∞...")

try:
    import pickle
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    log("‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–¥–µ–Ω–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.")
except Exception as e:
    log("‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:")
    log(traceback.format_exc())
    raise

try:
    log("üìÇ –ó–∞—Ä–µ–∂–¥–∞–º —Ç–µ–∫—Å—Ç–æ–≤–µ—Ç–µ –æ—Ç joomla_clean_chunks.txt...")
    with open("joomla_clean_chunks.txt", "r", encoding="utf-8") as f:
        chunks = [line.strip() for line in f if line.strip()]
    log(f"‚úÖ –ó–∞—Ä–µ–¥–µ–Ω–∏ {len(chunks)} —Ç–µ–∫—Å—Ç–∞.")
except Exception as e:
    log("‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–µ—Ç–µ:")
    log(traceback.format_exc())
    raise

try:
    log("‚öôÔ∏è –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–∞–Ω–µ...")
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(chunks)
    log("‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è—Ç–∞ –µ –≥–æ—Ç–æ–≤–∞.")
except Exception as e:
    log("‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è—Ç–∞:")
    log(traceback.format_exc())
    raise

try:
    question = "–ö–∞–∫–≤–æ –µ HTML?"
    log(f"‚ùì –í—ä–ø—Ä–æ—Å: {question}")
    question_vec = vectorizer.transform([question])
    similarities = cosine_similarity(question_vec, X)
    best_idx = similarities.argmax()
    answer = chunks[best_idx]
    log(f"üí° –û—Ç–≥–æ–≤–æ—Ä: {answer}")
except Exception as e:
    log("‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –Ω–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ –æ—Ç–≥–æ–≤–æ—Ä:")
    log(traceback.format_exc())
    raise

log("üèÅ –°–∫—Ä–∏–ø—Ç—ä—Ç –ø—Ä–∏–∫–ª—é—á–∏ —É—Å–ø–µ—à–Ω–æ.")
